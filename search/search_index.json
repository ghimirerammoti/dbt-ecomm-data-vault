{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"\ud83e\uddf1 dbt Data Vault 2.0 \u2014 eCommerce Analytics Project \ud83e\udded Overview This project demonstrates how to implement a Data Vault 2.0 architecture using dbt to model data from multiple sources in the eCommerce and logistics domain. It integrates data from: - \ud83d\uded2 Shopify (sales, products, customers) - \ud83d\ude9a 3PL Logistics (SALSA) (Fulfillments, tracking, Delivery) - \ud83c\udfe2 Centic Software (Planning, Inventory) - \ud83d\udcb0 Finance/Accounting systems (Oracle Fusion ERP) The models are deployed and orchestrated using ApacheAirflow- Managed in AWS and tested in Snowflake . \ud83e\uddf1 Architecture - Staging Layer : Standardized, cleaned data from each source - Hubs : Business keys (e.g., customer, order, product) - Links : Relationships (e.g., order \u2194 products) - Satellites : Contextual details (e.g., order status, address, payment) - Marts : Flattened, analytics-ready views, materialized views \ud83e\uddf0 Tech Stack Component Tool/Service Modeling dbt (Core + Cloud) Warehouse Snowflake Orchestration ApacheAirflow - AWS Managed Ingestion Python Custom Versioning GitHub Testing dbt tests , snapshots \ud83d\ude80 How to Run ````bash 1. Clone the repo git clone https://github.com/motiramgh/DBT-ECOMM-DATA-VAULT.git cd DBT-ECOMM-DATA-VAULT 2. Update ~/.dbt/profiles.yml: ecomm_data_vault: target: dev outputs: dev: type: snowflake account: user: password: role: database: warehouse: schema: threads: 4 client_session_keep_alive: false 3. Install dbt and Dependencies & Project Packages pip install dbt-snowflake dbt deps 4. To populate static reference data: dbt seed 5. Run Staging Models dbt run --select stage 6. Run Vault Models dbt run --select vault Or run a specific component: dbt run --select +hub_order 7. Run Data Marts (Optional) If you've defined any marts or reporting layers: dbt run --select marts 8. Run All Models (Full Pipeline) dbt run 9. Run Tests dbt test 10. Generate and View Documentation dbt docs generate dbt docs serve","title":"\ud83e\uddf1 dbt Data Vault 2.0 \u2014 eCommerce Analytics Project"},{"location":"index.html#dbt-data-vault-20-ecommerce-analytics-project","text":"","title":"\ud83e\uddf1 dbt Data Vault 2.0 \u2014 eCommerce Analytics Project"},{"location":"index.html#overview","text":"This project demonstrates how to implement a Data Vault 2.0 architecture using dbt to model data from multiple sources in the eCommerce and logistics domain. It integrates data from: - \ud83d\uded2 Shopify (sales, products, customers) - \ud83d\ude9a 3PL Logistics (SALSA) (Fulfillments, tracking, Delivery) - \ud83c\udfe2 Centic Software (Planning, Inventory) - \ud83d\udcb0 Finance/Accounting systems (Oracle Fusion ERP) The models are deployed and orchestrated using ApacheAirflow- Managed in AWS and tested in Snowflake .","title":"\ud83e\udded Overview"},{"location":"index.html#architecture","text":"- Staging Layer : Standardized, cleaned data from each source - Hubs : Business keys (e.g., customer, order, product) - Links : Relationships (e.g., order \u2194 products) - Satellites : Contextual details (e.g., order status, address, payment) - Marts : Flattened, analytics-ready views, materialized views","title":"\ud83e\uddf1 Architecture"},{"location":"index.html#tech-stack","text":"Component Tool/Service Modeling dbt (Core + Cloud) Warehouse Snowflake Orchestration ApacheAirflow - AWS Managed Ingestion Python Custom Versioning GitHub Testing dbt tests , snapshots","title":"\ud83e\uddf0 Tech Stack"},{"location":"index.html#how-to-run","text":"````bash","title":"\ud83d\ude80 How to Run"},{"location":"index.html#1-clone-the-repo","text":"git clone https://github.com/motiramgh/DBT-ECOMM-DATA-VAULT.git cd DBT-ECOMM-DATA-VAULT","title":"1. Clone the repo"},{"location":"index.html#2-update-dbtprofilesyml","text":"ecomm_data_vault: target: dev outputs: dev: type: snowflake account: user: password: role: database: warehouse: schema: threads: 4 client_session_keep_alive: false","title":"2. Update ~/.dbt/profiles.yml:"},{"location":"index.html#3-install-dbt-and-dependencies-project-packages","text":"pip install dbt-snowflake dbt deps","title":"3. Install dbt and Dependencies &amp; Project Packages"},{"location":"index.html#4-to-populate-static-reference-data","text":"dbt seed","title":"4. To populate static reference data:"},{"location":"index.html#5-run-staging-models","text":"dbt run --select stage","title":"5. Run Staging Models"},{"location":"index.html#6-run-vault-models","text":"dbt run --select vault","title":"6. Run Vault Models"},{"location":"index.html#or-run-a-specific-component","text":"dbt run --select +hub_order","title":"Or run a specific component:"},{"location":"index.html#7-run-data-marts-optional","text":"","title":"7. Run Data Marts (Optional)"},{"location":"index.html#if-youve-defined-any-marts-or-reporting-layers","text":"dbt run --select marts","title":"If you've defined any marts or reporting layers:"},{"location":"index.html#8-run-all-models-full-pipeline","text":"dbt run","title":"8. Run All Models (Full Pipeline)"},{"location":"index.html#9-run-tests","text":"dbt test","title":"9. Run Tests"},{"location":"index.html#10-generate-and-view-documentation","text":"dbt docs generate dbt docs serve","title":"10. Generate and View Documentation"}]}